//Source config

//URL for gateway to cluster with source data.
//Requirement is that the terminal running the dev_cluster tool has valid security credentials
//to access this via password-less SSH, and may run HDFS and Hive commands on it.
address = ""

//Algorithm to copy from source to dev cluster.  Note that one could just use distcp, but there might be
//security limitations on both clusters preventing this from happening.
//"tunnel" copies to local machine and then the dev cluster.
//"bucket" copies first to a temp bucket secured with provided AWS credentials in target-aws.xml, and then to dev cluster (in development).
//"local" copies directly local files to the dev cluster
copy {
  scheme = tunnel
  sample.threshold = 500000000
  //If set true, when a file to be copied exists, it will be overwritten
  overwriteIfExists = true
}

//Sampling properties
default {
  sample.prob = 0.01
  partition.count = -1
}
sample.database = dev_cluster_sample
s3.hdfs.scheme = s3a

//Array of "database"."table".
//For each table, partitions is optional, if it is specified, it will be passed to Hive to only fetch matching //partitions that match (up to the partition count).
//Multiple partitions may be passed, and all matching partitions will be returned (up to the partition count).
tables = [
  {
    name = "db.table",
    partitions = [
      [
        "day='2000-01-01'","hour=24"
      ]
    ]
    sample.prob = 0.01
    partition.count = 2
  },
  {
    name = "db.table2"
    // use this option to prevent the table/partitions from being removed in cleanup
    skip.cleanup = true
  }
]

//Arrayof listeners to run on copy action, ex, handle special formats
//Copies over pail.meta file.  This goes along with criteo-cluster conf,
//which sets the default Hive input format to be PailOrCombineInputFormat.
copy.listeners = []

//This alters the sample table (if a glup table) to also write data in glup format to the final destination.
sample.listeners = []

//Configure gateway to access a Hadoop cluster.
gateway {
  //Array of additional ports to be opened on gateway.
  //Port specs are of the form "$port_description/$exposed_port_num:$portNum"
  //$port_description is optional and used for display in list-gateway.
  //$exposed_port_num is optional, and will provide a hard-binding.
  docker.ports = []

  //Array of additional docker files to run to set up the gateway.
  //DockerFiles must start with line "FROM dev_cluster/gateway"
  //and be located under /docker/contrib-gateway.
  docker.files = []

  //Given a command "dev-cluster gateway $mycluster", it will search for this directory to get the Hadoop/Hive client conf. The directory would be located under ./hadoop-resources/hadoop-conf/
  gateway.mycluster.conf = mycluster
}

parallelism {
  //The number of the threads are used to copy tables
  table = 1
  //The number of the threads are used to copy partitions per table
  partition = 1
}

//Target config

//Name of a directory (under ./hadoop-resources) that will has hadoop conf that dev cluster will spawn with.
//Make sure you create the folder as a copy of the default conf at ./hadoop-resources/cluster-default, which has
//the minimum configuration to spawn a cloud CDH cluster.

//You can then add your own configurations to the specific conf-xml file as you like.
//Variables you may use include $master (will be replaced by the cluster master hostname)
//and $local (will be replaced by the local node's host name).
hadoop.conf.dir = ""

//Comma separated list of jars needed to be added to Hive aux jar path on dev clusters and gateways.
//These need to be placed under ./hadoop-resources/aux-jars
hive.aux.jars = [
  ""
]

//CDH version to download.
//For now we only support CDH5 repositories of ubuntu trusty.
//This would have to be a valid version listed under:
//http://archive.cloudera.com/cdh5/ubuntu/trusty/amd64/cdh/dists/
hadoop.version = cdh5.5.0
base.os = ubuntu-trusty


//For docker
local {
  // This is comma-delimited list of dockerFiles located under
  //./docker/contrib-cluster.  Must start with 'FROM dev_cluster/local'.
  docker.files = [
  ]
  docker.containerId = "id"

  //Comma separated list of additional ports to be opened on the local cluster container.
  //Port specs are of the form "$port_description/$portNum"
  //$port_description is optional, and is used for display in command list-local.
  ports = [
    "SampleAppWeb/7000",
    "SampleAppAdmin/7001"
  ]
  cluster.user = "root"
}

//For AWS
aws {
  //The user to use to ssh into the dev cluster.
  //This is determined by the base Ubuntu image(s) specified in base.image.id.
  user = ubuntu

  access.id = "id"
  access.id = ${?AWS_ACCESS_ID} //From the environment variable

  access.key = "key"
  access.key = ${?AWS_ACCESS_KEY}

  //Instance type to use in dev cluster.
  instance.type = m4.2xlarge

  //Volume spec of master and slave
  volume.spec = {
    master = [
      {
        name = "/dev/sda1"
        size = 100 // in MB
      },
      {
        name = "/dev/sdb"
        size = 500
      }
    ],
    slave = [
      {
        name = "/dev/sda1"
        size = 50
      },
      {
        name = "/dev/sdb"
        size = 500
      }
    ]
  }

  //If true and target.aws.volume.spec is set to a list of volumes in addition to root volume,
  //then extra volumes will be automatically mounted on the instance, and configured to be balanced
  //on each data node.
  auto.volumes = true

  //AWS region in which instances will be spawned
  region = eu-west-1

  //AWS subnet in which instances will be spawned
  subnet = ""

  //AWS security group instances to be assigned to
  security.group = ""

  //Name of AWS security key pair instances will be spawned with.  The corresponding key must be provided.
  key.pair = my_key_pair
  key.file = ./path/to/key

  //Public Ubuntu 14.04 public image of eu-west data center.
  base.image.id = ami-ed82e39e
}

s3.bucket.prefix = dev-cluster